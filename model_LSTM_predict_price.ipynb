{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from analytical_functions import create_open_close_df, cm_and_classification_report, generateshortDateTimeStamp\n",
    "from eda_functions import feature_importance_plot\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from contextlib import redirect_stdout\n",
    "np.random.seed(90210)\n",
    "tf.random.set_seed(90210)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing the data to train and test-set, ~66.67% train and 33.33% test <br>\n",
    "The data is scaled according to the train-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and scaling data\n",
    "ts = generateshortDateTimeStamp()\n",
    "feature_matrix_full = pd.read_csv('data/dfs/features.csv')\n",
    "y = pd.read_csv('data/dfs/y_label.csv')\n",
    "\n",
    "feature_importance = feature_importance_plot(feature_matrix_full, y, to_show=False)\n",
    "# Selecting only the top 75 features \n",
    "# important_features = feature_importance['Feature'].values[:75]\n",
    "# feature_matrix = feature_matrix_full[important_features].copy(deep=True)\n",
    "# Selecting all features\n",
    "feature_matrix = feature_matrix_full.copy(deep=True)\n",
    "\n",
    "n_features = len(list(feature_matrix))\n",
    "n_rows_train = 1175\n",
    "n_rows_test = 588\n",
    "\n",
    "x_train = feature_matrix.head(n_rows_train).copy(deep=True)\n",
    "y_train_series = y.head(n_rows_train).copy(deep=True)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler.fit(x_train)\n",
    "scaler_target = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler_target.fit(y_train_series.values)\n",
    "\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "y_train_scaled = scaler_target.transform(y_train_series.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used <b>featuretools</b> for automatic feature generation, and used a <b>tree-based</b> algorithm to estimate <b>feature importance</b><br>\n",
    "I've trained the model with full and partial features-set according to the importance. <br>\n",
    "Even when using fewer features, the model still gets good results.<br>\n",
    "The <b>featuretools</b> script is in a different file to make reading easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# LSTM - preparing dataset\n",
    "##########################################################################################\n",
    "# epochs = 10\n",
    "# look_back = 10\n",
    "epochs = 20\n",
    "look_back = 30\n",
    "batch_size = 50\n",
    "X_train = []\n",
    "y_train_as_arr = y_train_scaled.ravel()\n",
    "y_train = []\n",
    "for i in range(look_back, n_rows_train):\n",
    "    X_train.append(x_train_scaled[i - look_back:i])\n",
    "    y_train.append(y_train_as_arr[i])\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], n_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the dataset for LSTM (both train and labels) using look_back parameter to determine the number <br>\n",
    "of states back our model will consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1145/1145 [==============================] - 7s 6ms/step - loss: 0.0557\n",
      "Epoch 2/20\n",
      "1145/1145 [==============================] - 5s 5ms/step - loss: 0.0211\n",
      "Epoch 3/20\n",
      "1145/1145 [==============================] - 5s 5ms/step - loss: 0.0173\n",
      "Epoch 4/20\n",
      "1145/1145 [==============================] - 6s 5ms/step - loss: 0.0169\n",
      "Epoch 5/20\n",
      "1145/1145 [==============================] - 5s 5ms/step - loss: 0.0152\n",
      "Epoch 6/20\n",
      "1145/1145 [==============================] - 5s 5ms/step - loss: 0.0142\n",
      "Epoch 7/20\n",
      "1145/1145 [==============================] - 5s 5ms/step - loss: 0.0150\n",
      "Epoch 8/20\n",
      "1145/1145 [==============================] - 5s 5ms/step - loss: 0.0143\n",
      "Epoch 9/20\n",
      "1145/1145 [==============================] - 5s 5ms/step - loss: 0.0125\n",
      "Epoch 10/20\n",
      "1145/1145 [==============================] - 5s 5ms/step - loss: 0.0124\n",
      "Epoch 11/20\n",
      "1145/1145 [==============================] - 5s 5ms/step - loss: 0.0127\n",
      "Epoch 12/20\n",
      "1145/1145 [==============================] - 6s 5ms/step - loss: 0.0110\n",
      "Epoch 13/20\n",
      "1145/1145 [==============================] - 5s 5ms/step - loss: 0.0107\n",
      "Epoch 14/20\n",
      "1145/1145 [==============================] - 6s 5ms/step - loss: 0.0110\n",
      "Epoch 15/20\n",
      "1145/1145 [==============================] - 6s 5ms/step - loss: 0.0106\n",
      "Epoch 16/20\n",
      "1145/1145 [==============================] - 5s 5ms/step - loss: 0.0107\n",
      "Epoch 17/20\n",
      "1145/1145 [==============================] - 5s 5ms/step - loss: 0.0100\n",
      "Epoch 18/20\n",
      "1145/1145 [==============================] - 5s 5ms/step - loss: 0.0098\n",
      "Epoch 19/20\n",
      "1145/1145 [==============================] - 5s 5ms/step - loss: 0.0106\n",
      "Epoch 20/20\n",
      "1050/1145 [==========================>...] - ETA: 0s - loss: 0.0106"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "# LSTM Model\n",
    "##########################################################################################\n",
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[1], n_features)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units=50, return_sequences=True, activation='relu'))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units=25))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(units=1))\n",
    "\n",
    "regressor.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "regressor.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "# Always save model architecture\n",
    "plot_model(regressor, to_file=f'output/{ts}_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the results of price prediction on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Train stock price visualization\n",
    "##########################################################################################\n",
    "predicted_train_scaled_stock_price = regressor.predict(X_train, batch_size=batch_size)\n",
    "predicted_train_stock_price = scaler_target.inverse_transform(predicted_train_scaled_stock_price)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(0, len(y_train_series)), y_train_series.values, color='black', label='Rice Stock Price')\n",
    "plt.plot(range(look_back, len(predicted_train_stock_price)+look_back), predicted_train_stock_price, color='green', \n",
    "         label='Predicted Rice Stock Price')\n",
    "plt.title('Rice Stock Price Prediction')\n",
    "plt.xlabel('Time', fontsize=14)\n",
    "plt.ylabel('Rice Stock Price', fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model very closely predicts the prices, though this can also be overfitting. <br>\n",
    "We'll look at the prediction on the test set to verify our results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing test-set data in a similar way to the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Test\n",
    "##########################################################################################\n",
    "feature_matrix_scaled = scaler.transform(feature_matrix)\n",
    "inputs = feature_matrix_scaled[len(feature_matrix_scaled) - n_rows_test - look_back:]\n",
    "\n",
    "X_test = []\n",
    "for i in range(look_back, n_rows_test):\n",
    "    X_test.append(inputs[i-look_back:i])\n",
    "x_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And predicting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test_scaled_stock_price = regressor.predict(x_test, batch_size=batch_size)\n",
    "predicted_test_stock_price = scaler_target.inverse_transform(predicted_test_scaled_stock_price)\n",
    "y_test_series = y.tail(n_rows_test).copy(deep=True)\n",
    "y_test = y_test_series.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(0, len(y_test)), y_test, color='blue', label='Rice Stock Price test')\n",
    "plt.plot(range(0, len(predicted_test_stock_price)), predicted_test_stock_price.ravel(), color='purple', \n",
    "         label='Predicted Rice Stock Price test')\n",
    "plt.title('Rice Stock Price Prediction')\n",
    "plt.xlabel('Time', fontsize=14)\n",
    "plt.ylabel('Rice Stock Price', fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome :) Our model appears to have captured the main trends quite accurately!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point of view it seems that the model is handling the data very well.<br>\n",
    "The main trends are very closely tracked, with a small range of error, but...! <br>\n",
    "Is predicting the price accurately the appropriate measurement? <br>\n",
    "<br>\n",
    "The truth is, that from a business point of view it might be more useful to know if the stock<br>\n",
    "is going <b>up</b> or <b>down</b>. The is, if we can predict that the stock will <b>CLOSE</b> at<br>\n",
    "a higher rate than its <b>OPENING</b> price, it would have an immense business value. We would <br>\n",
    "probably buy the stock, and sell the next day. Or have any number of long/short term strategies <br>\n",
    "<br>\n",
    "Moreover, this reveals the weakness in using <b>MAE</b> for prediction. What if we predicted <br>\n",
    "the prices <i>almost</i> accurately? By \"almost\" I mean, that we might get the trend wrong.<br>\n",
    "Predict up, when the stock is going down, and vise-versa. In such a scenario, even if we <br>\n",
    "prected a very close price, we'll end up losing money all the time.<br>\n",
    "We can also see that our model tends to be smoother, which means we'll be missing out on <br>\n",
    "a lot of the action going on. Especially the three steep \"crashes\" of the stock to the price<br>\n",
    "of 27.5, which could have been a great point to buy some stock, but our model's prediction <br>\n",
    "are too smooth, and we might miss the opportunity.<br>\n",
    "\n",
    "Therefore, I selected to use (<b>CLOSE</b>-<b>OPEN</b> > thr) price as a categorical target. <b>thr</b><br>\n",
    "is a sort of profitability margin. If the stock goes up, but only by very little, then it might <br>\n",
    "be unprofitable to buy due to the overhead around buying and selling (fees, taxes, etc.)<br>\n",
    "For the simplicity of this assignment, thr = 0, but it can be easily changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Here we'll be calculating both <b>MAE</b> and <b>categorical</b> variables and inspect them for<br>\n",
    "both train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_original_features: pd.DataFrame = feature_matrix_full.tail(n_rows_test - look_back).copy(deep=True)\n",
    "train_binary_class_df = create_open_close_df(x_train['Open'].values[look_back:], y_train_series.values.ravel()[look_back:], \n",
    "                                             predicted_train_stock_price.ravel())\n",
    "test_binary_class_df = create_open_close_df(test_original_features['Open'].values, y_test.ravel()[:-look_back], \n",
    "                                            predicted_test_stock_price.ravel())\n",
    "\n",
    "mae_train = mean_absolute_error(y_train_series.values[look_back:], predicted_train_scaled_stock_price)\n",
    "mae_test = mean_absolute_error(y_test[:-look_back], predicted_test_stock_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing results to file and printing them to console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'output/' + ts + '.txt'\n",
    "with open(fname, 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        print(\"TRAIN\")\n",
    "        cm_and_classification_report(train_binary_class_df['hasStockGoneUp'].values, \n",
    "                                     train_binary_class_df['hasStockGoneUp_pred'].values, labels=[0, 1])\n",
    "        print(\"TEST\")\n",
    "        cm_and_classification_report(test_binary_class_df['hasStockGoneUp'].values, \n",
    "                                     test_binary_class_df['hasStockGoneUp_pred'].values, labels=[0, 1])\n",
    "        print(f\"\\nlook_back:\\t{look_back}\")\n",
    "        print(f\"batch_size:\\t{batch_size}\")\n",
    "        print(f\"epochs:\\t{epochs}\")\n",
    "        print(\"Train MAE: %.3f\" % mae_train)\n",
    "        print(\"Test MAE: %.3f\" % mae_test)\n",
    "f.close()\n",
    "with open(fname, 'r') as f:\n",
    "    print(f.read())\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using <b>hasStockGoneUp</b> we would aim to know, for most of the time, if the stock is about to go up, or not<br>\n",
    "and to some extent by how much (using the <b>thr</b> parameter)<br>\n",
    "The results of such a categorical approach gives interesting results. \n",
    "One one hand, the train seems to be completely off-base here. This might be due to the fact, that while <br>\n",
    "we captured well the main-trends, the actual behavior (up/down) is extremly noisy, which results in a bad,<br>\n",
    "confusion matrix, that seem almost random.<br>\n",
    "On the other hand, the test set, which predicted the prices less-accurately, shows great results<br>\n",
    "when looking for the trends. Given more time I'd investigate this further (and especially look for <br>\n",
    "bugs (for example, an unintentional shift in the look_back parameter may also cause this).<br>\n",
    "The results in the test-set as well as the graphs have good starting recall values, but can <br>\n",
    "be improved upon, with more time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Long term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more long-term solution I think that the current architecture definately shows a lot of promise, <i>but</i><br>\n",
    "I'll want to take advantage of more data, and this can come in two ways:<br>\n",
    "1) I'd like to get input from a domain expert, which is always a good idea. To try and see what more can <br>\n",
    "be done with the data we already have.<br>\n",
    "2) Add more data-sources, such as weather, news-feeds, more 'flavors' of sentiment and analysts input, as well as <br>\n",
    "trends in the specific industry. For example, in this case we can consider rice stock price related to both<br>\n",
    "rice prices world-wide, but also generally to the agriculture market, or similar crops.<br>\n",
    "3) In addition to domain experts, hand-crafted and semi-automatically generated features, I may also want<br>\n",
    "to try out a some CNN based-architecture to take advantage of the network's ability to find feature by itself.<br>\n",
    "4) Open and Close prices are not all of the story. Being able to accurately predict Low and High may also <br>\\\n",
    "be quite useful during the day and allow for some more dynamic strategies.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
